import json
import os
import httpx
import feedparser
from datetime import datetime
from pathlib import Path
from typing import Dict, List
from bs4 import BeautifulSoup
from nonebot import get_bot, require, on_command
from nonebot.adapters.onebot.v11 import MessageSegment, Message
from nonebot.params import CommandArg
from nonebot.plugin import PluginMetadata
from nonebot.log import logger
from apscheduler.schedulers.asyncio import AsyncIOScheduler

require("apscheduler")
scheduler = AsyncIOScheduler()

__plugin_meta__ = PluginMetadata(
    name="Twitterå®šæ—¶æ¨é€",
    description="å®šæ—¶æ¨é€Twitterç”¨æˆ·åŠ¨æ€åˆ°æŒ‡å®šç¾¤èŠ",
    usage=(
        "æ·»åŠ è®¢é˜…: /rss_sub <ç”¨æˆ·å> <ç¾¤å·> <é—´éš”åˆ†é’Ÿ>\n"
        "ç§»é™¤è®¢é˜…: /rss_unsub <ç”¨æˆ·å> <ç¾¤å·>\n"
        "åˆ—å‡ºè®¢é˜…: /rss_list\n"
        "ç¤ºä¾‹: /rss_sub aibaaiai 123456 60"
    ),
    type="application",
    homepage="https://github.com/your/repo",
)

# é…ç½®æ–‡ä»¶è·¯å¾„
DATA_PATH = Path("data/twitter_rss")
SUB_FILE = DATA_PATH / "subscriptions.json"

# åˆå§‹åŒ–æ•°æ®ç›®å½•
DATA_PATH.mkdir(parents=True, exist_ok=True)

# é…ç½®é¡¹
RSSHUB_HOST = "https://rsshub.app"  # RSSHubå®ä¾‹
CHECK_INTERVAL = 30  # é»˜è®¤æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
MAX_HISTORY = 5  # æœ€å¤§å†å²è®°å½•å­˜å‚¨æ•°é‡


class SubscriptionManager:
    def __init__(self):
        self.subscriptions: Dict[str, List[dict]] = {}
        self.history: Dict[str, List[str]] = {}
        self.load_data()

    def load_data(self):
        """åŠ è½½è®¢é˜…æ•°æ®"""
        try:
            if SUB_FILE.exists():
                with open(SUB_FILE, "r") as f:
                    data = json.load(f)
                    self.subscriptions = data.get("subscriptions", {})
                    self.history = data.get("history", {})
        except Exception as e:
            logger.error(f"åŠ è½½è®¢é˜…æ•°æ®å¤±è´¥: {e}")

    def save_data(self):
        """ä¿å­˜è®¢é˜…æ•°æ®"""
        try:
            with open(SUB_FILE, "w") as f:
                json.dump({
                    "subscriptions": self.subscriptions,
                    "history": self.history
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è®¢é˜…æ•°æ®å¤±è´¥: {e}")

    def add_subscription(self, username: str, group_id: str, interval: int):
        """æ·»åŠ è®¢é˜…"""
        key = f"{username}_{group_id}"
        job_id = f"rss_job_{key}"

        # ç§»é™¤ç°æœ‰ä»»åŠ¡
        self.remove_subscription(username, group_id)

        # æ·»åŠ æ–°ä»»åŠ¡
        scheduler.add_job(
            self.check_update,
            "interval",
            minutes=interval,
            id=job_id,
            args=(username, group_id),
            replace_existing=True
        )

        # æ›´æ–°è®¢é˜…æ•°æ®
        self.subscriptions[key] = {
            "username": username,
            "group_id": group_id,
            "interval": interval,
            "last_checked": datetime.now().isoformat()
        }
        self.save_data()

    def remove_subscription(self, username: str, group_id: str):
        """ç§»é™¤è®¢é˜…"""
        key = f"{username}_{group_id}"
        job_id = f"rss_job_{key}"

        if scheduler.get_job(job_id):
            scheduler.remove_job(job_id)

        if key in self.subscriptions:
            del self.subscriptions[key]
            self.save_data()
            return True
        return False

    async def check_update(self, username: str, group_id: str):
        """æ‰§è¡Œæ£€æŸ¥æ›´æ–°"""
        try:
            feed_url = f"{RSSHUB_HOST}/twitter/user/{username}"

            async with httpx.AsyncClient(timeout=20) as client:
                resp = await client.get(feed_url)
                feed = feedparser.parse(resp.content)

            if not feed.entries:
                return

            latest_entry = feed.entries[0]
            entry_id = latest_entry.id

            # æ£€æŸ¥æ˜¯å¦æ–°å†…å®¹
            history = self.history.get(username, [])
            if entry_id in history:
                return

            # å¤„ç†æ–°å†…å®¹
            content = self.parse_entry(latest_entry)
            await self.send_to_group(group_id, content)

            # æ›´æ–°å†å²è®°å½•
            self.update_history(username, entry_id)

        except Exception as e:
            logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")

    def update_history(self, username: str, entry_id: str):
        """æ›´æ–°å†å²è®°å½•"""
        self.history.setdefault(username, [])
        self.history[username].append(entry_id)
        # ä¿æŒæœ€å¤§å†å²è®°å½•æ•°é‡
        if len(self.history[username]) > MAX_HISTORY:
            self.history[username] = self.history[username][-MAX_HISTORY:]
        self.save_data()

    def parse_entry(self, entry) -> dict:
        """è§£ææ¨æ–‡å†…å®¹"""
        published = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d %H:%M")

        clean_text = BeautifulSoup(entry.description, "html.parser").get_text("\n").strip()

        images = []
        for media in getattr(entry, "media_content", []):
            if media.get("type", "").startswith("image/"):
                images.append(media["url"])

        return {
            "title": entry.title,
            "time": published,
            "link": entry.link,
            "text": clean_text,
            "images": images[:3]
        }

    async def send_to_group(self, group_id: str, content: dict):
        """å‘é€æ¶ˆæ¯åˆ°ç¾¤èŠ"""
        try:
            bot = get_bot()
            # æ–‡å­—æ¶ˆæ¯
            msg = [
                f"ğŸ¦ æ–°æ¨æ–‡æ¨é€ [{content['time']}]",
                f"ğŸ“Œ {content['title']}",
                f"ğŸ”— {content['link']}",
                "\nğŸ“ å†…å®¹ï¼š",
                content['text']
            ]
            await bot.send_group_msg(group_id=int(group_id), message="\n".join(msg))

            # å›¾ç‰‡æ¶ˆæ¯
            for img_url in content["images"]:
                async with httpx.AsyncClient(timeout=15) as client:
                    resp = await client.get(img_url)
                    img_seg = MessageSegment.image(resp.content)
                    await bot.send_group_msg(group_id=int(group_id), message=img_seg)

        except Exception as e:
            logger.error(f"ç¾¤æ¶ˆæ¯å‘é€å¤±è´¥: {e}")


# åˆå§‹åŒ–è®¢é˜…ç®¡ç†å™¨
sub_manager = SubscriptionManager()

# å‘½ä»¤å¤„ç†å™¨
rss_sub = on_command("rss_sub", aliases={"è®¢é˜…æ¨ç‰¹"}, priority=10)
rss_unsub = on_command("rss_unsub", aliases={"å–æ¶ˆè®¢é˜…"}, priority=10)
rss_list = on_command("rss_list", aliases={"è®¢é˜…åˆ—è¡¨"}, priority=10)


@rss_sub.handle()
async def handle_subscribe(args: Message = CommandArg()):
    """æ·»åŠ è®¢é˜…"""
    params = args.extract_plain_text().strip().split()
    if len(params) != 3:
        await rss_sub.finish("å‚æ•°æ ¼å¼é”™è¯¯ï¼Œæ­£ç¡®æ ¼å¼ï¼š/rss_sub <ç”¨æˆ·å> <ç¾¤å·> <é—´éš”åˆ†é’Ÿ>")

    username, group_id, interval = params
    if not interval.isdigit():
        await rss_sub.finish("é—´éš”æ—¶é—´å¿…é¡»ä¸ºæ•´æ•°åˆ†é’Ÿ")

    sub_manager.add_subscription(username, group_id, int(interval))
    await rss_sub.send(
        f"âœ… è®¢é˜…æˆåŠŸ\n"
        f"ç”¨æˆ·å: {username}\n"
        f"æ¨é€ç¾¤ç»„: {group_id}\n"
        f"æ£€æŸ¥é—´éš”: {interval}åˆ†é’Ÿ"
    )


@rss_unsub.handle()
async def handle_unsubscribe(args: Message = CommandArg()):
    """å–æ¶ˆè®¢é˜…"""
    params = args.extract_plain_text().strip().split()
    if len(params) != 2:
        await rss_unsub.finish("å‚æ•°æ ¼å¼é”™è¯¯ï¼Œæ­£ç¡®æ ¼å¼ï¼š/rss_unsub <ç”¨æˆ·å> <ç¾¤å·>")

    username, group_id = params
    if sub_manager.remove_subscription(username, group_id):
        await rss_unsub.send(f"âœ… å·²å–æ¶ˆ {username} å¯¹ç¾¤ç»„ {group_id} çš„è®¢é˜…")
    else:
        await rss_unsub.send("âŒ æœªæ‰¾åˆ°å¯¹åº”çš„è®¢é˜…è®°å½•")


@rss_list.handle()
async def handle_list():
    """åˆ—å‡ºè®¢é˜…"""
    if not sub_manager.subscriptions:
        await rss_list.finish("å½“å‰æ²¡æœ‰æ´»è·ƒè®¢é˜…")

    msg = ["ğŸ“‹ å½“å‰è®¢é˜…åˆ—è¡¨ï¼š"]
    for sub in sub_manager.subscriptions.values():
        msg.append(
            f"Â· {sub['username']} â†’ ç¾¤ç»„ {sub['group_id']} "
            f"(æ¯ {sub['interval']} åˆ†é’Ÿæ£€æŸ¥)"
        )

    await rss_list.send("\n".join(msg))


# å¯åŠ¨å®šæ—¶ä»»åŠ¡
scheduler.start()
logger.info("Twitterå®šæ—¶æ¨é€æœåŠ¡å·²å¯åŠ¨")


# æ’ä»¶å¸è½½æ—¶ä¿å­˜æ•°æ®
def on_unload():
    sub_manager.save_data()